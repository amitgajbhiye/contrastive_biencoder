{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a056e-c2b8-4627-aa2f-b0213907e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407da99a-8ba9-469e-8da9-b9fd986b36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file_path = \"/home/amitgajbhiye/cardiff_work/data/CSLB_Property_Norms_V1.1/norms.dat\"\n",
    "hawk_file_path = \"CSLB_Property_Norms_V1.1/norms.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c739e-7f12-48f6-b965-38d64484e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(concept, feature_alternatives, participant_list):\n",
    "    \n",
    "    # print (concept)\n",
    "    # print (feature_alternatives.split(\";\"))\n",
    "    # print (participant_list.split(\"/\"))\n",
    "    # print ()\n",
    "    \n",
    "    # print (f\"Processing Record : {concept, feature_alternatives, participant_list}\")\n",
    "    feature_list = feature_alternatives.split(\";\")\n",
    "    feature_list = [x.strip() for x in feature_list]\n",
    "    # print (f\"feature_list : {feature_list}\")\n",
    "    participant_list = participant_list.split(\"/\")\n",
    "    # print (f\"participant_list 1: {participant_list}\")\n",
    "    participant_list = [len(x.replace(\"p\", \"\").strip().split()) for x in participant_list]\n",
    "    # print (f\"participant_list 2: {participant_list}\")\n",
    "    \n",
    "    max_value = max (participant_list)\n",
    "    # print (f\"max_value : {max_value}\")\n",
    "    \n",
    "    concept_data = []\n",
    "    if max_value >= 3:\n",
    "        max_index = participant_list.index(max_value)\n",
    "        # print (\"feature_list :\", feature_list)\n",
    "        # print (f\"max_index :\", {max_index})\n",
    "        # print (f\"max_value : {max_value}\")\n",
    "        feature = feature_list[max_index]\n",
    "        # print (f\"feature_list : {feature_list}\")\n",
    "        # print (f\"feature: {feature}\")\n",
    "        # print ()\n",
    "        \n",
    "        concept_data.append((concept.strip(), feature.strip(), max_value))\n",
    "    \n",
    "    return concept_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db9b83d-e062-450e-b4b2-bf5aa7a0a4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cslb_processing(file_path):\n",
    "    \n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", header=\"infer\")\n",
    "    \n",
    "    all_data_list = [process_row(row[0], row[1], row[2]) for row in zip(df[\"concept\"], df[\"feature alternatives\"], df[\"participant list\"])]\n",
    "    \n",
    "    all_data_list = [con_feature_count for sublist in all_data_list for con_feature_count in sublist]\n",
    "    # print (all_data_list)\n",
    "    \n",
    "    all_data_df = pd.DataFrame.from_records(all_data_list, columns=[\"concept\", \"property\", \"participant_count\"])\n",
    "    \n",
    "    \n",
    "    print (\"Original CSLB Dataframe size : \", df.shape)\n",
    "    print (\"Processed Data Before Removing Duplicates :\", all_data_df.shape)\n",
    "    \n",
    "    duplicated_df = all_data_df.loc[all_data_df.duplicated(subset = [\"concept\", \"property\"], keep=False)]\n",
    "    duplicates_df_idx = duplicated_df.index\n",
    "    \n",
    "    all_data_df = all_data_df.drop(index=duplicates_df_idx)\n",
    "    all_data_df = all_data_df.dropna(axis=0, how=\"any\")\n",
    "    all_data_df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    print (\"Duplicated Data :\", duplicated_df.shape)\n",
    "    \n",
    "    print (\"Data after After Removing Duplicates :\", all_data_df.shape)\n",
    "    \n",
    "    return all_data_df\n",
    "\n",
    "df_cslb = cslb_processing(file_path=hawk_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7b1e1-5e77-456a-aced-b101abff6086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (df_cslb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c3605-1f95-4b70-b014-b71d1742eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cslb.drop(\"participant_count\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88198d9c-a72e-4fcf-939c-ac7791c31212",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cslb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6e7d0-28ae-46e0-a6b6-22d0c63c10eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def negative_sampling(df, data_type, num_negative=5):\n",
    "    \n",
    "    pos_data_list = df.values.tolist()\n",
    "    \n",
    "    df[\"label\"] = int(1)\n",
    "    \n",
    "    # df.reset_index(drop=True, inplace=True)\n",
    "    print (df.shape)\n",
    "    print (df.head())\n",
    "    print ()\n",
    "    \n",
    "    unique_concepts = df[\"concept\"].unique()\n",
    "    unique_properties = df[\"property\"].unique()\n",
    "    \n",
    "    print (f\"Number of Unique Concepts in Dataframe :\", len(unique_concepts), flush=True)\n",
    "    \n",
    "    all_negative_data = []\n",
    "    \n",
    "    for concept in unique_concepts:\n",
    "        \n",
    "        concept_data = df[df[\"concept\"] == concept]\n",
    "        properties_for_concept = concept_data[\"property\"].unique()\n",
    "        \n",
    "        num_record = len(concept_data)\n",
    "        \n",
    "        print()\n",
    "        print (f\"Generating Negative Data for Concept : {concept}\", flush=True)\n",
    "        print (f\"Positive data for concept in DF : {concept_data.shape}\", flush=True)\n",
    "        \n",
    "        print (\"Data For concept\", flush=True)\n",
    "        print (concept_data, flush=True)\n",
    "        print (f\"Properties for Concept\", flush=True)\n",
    "        print(properties_for_concept, flush=True)\n",
    "        \n",
    "        total_neg_num = num_record * num_negative\n",
    "        \n",
    "        print (f\"Total Number of Negative Records to be generated : {total_neg_num}\")\n",
    "        \n",
    "        \n",
    "        rest_df = df[df[\"concept\"] != concept]\n",
    "        print (f\"Rest DF shape after removing concept : {rest_df.shape}\")\n",
    "        rest_df = rest_df[~rest_df[\"property\"].isin(properties_for_concept)]\n",
    "        \n",
    "        print (f\"Rest DF shape after removing concepts's properties : {rest_df.shape}\", flush=True)\n",
    "        \n",
    "        concept_neg_data = []\n",
    "        \n",
    "        while (True):\n",
    "            \n",
    "            concept = concept.strip()\n",
    "            neg_properties = list(rest_df[\"property\"].sample(n = total_neg_num))\n",
    "            \n",
    "            neg_data = [[concept, neg_prop] for neg_prop in neg_properties]\n",
    "            print (f\"neg_data length :\", len(neg_data), flush=True)\n",
    "            \n",
    "            if len(concept_neg_data) < total_neg_num:\n",
    "                for x in neg_data:\n",
    "                    if not (x in pos_data_list):\n",
    "                        if not (x in all_negative_data):\n",
    "\n",
    "                            all_negative_data.append(x)\n",
    "                            concept_neg_data.append(x)\n",
    "                            \n",
    "                            if len(concept_neg_data) == total_neg_num:\n",
    "                                break\n",
    "                                \n",
    "            if len(concept_neg_data) == total_neg_num:\n",
    "                break\n",
    "            \n",
    "        print (f\"Number of negative records generated : {len(concept_neg_data)}\", flush=True)\n",
    "        print (f\"Negative Records\", flush=True)\n",
    "        print (concept_neg_data, flush=True)\n",
    "        print ()\n",
    "                        \n",
    "    \n",
    "    _ = [x.insert(2, int(0)) for x in all_negative_data]\n",
    "    \n",
    "    # print (\"all_negative_data\")\n",
    "    # print (all_negative_data)\n",
    "                                        \n",
    "    all_neg_data_df = pd.DataFrame.from_records(all_negative_data, columns=[\"concept\", \"property\", \"label\"])\n",
    "    \n",
    "    neg_data_duplicate_records = all_neg_data_df[all_neg_data_df.duplicated([\"concept\", \"property\"])]\n",
    "    \n",
    "    print ()\n",
    "    print (f\"all_neg_data_df.shape : {all_neg_data_df.shape}\", flush=True)\n",
    "    print (f\"neg_data_duplicate_records.shape : {neg_data_duplicate_records.shape}\", flush=True)\n",
    "    print ()\n",
    "        \n",
    "    print (f\"Checking overlap between positive and negative data\", flush=True)\n",
    "    pos_neg_overlap_df = df.merge(all_neg_data_df, how = 'inner', on = [\"concept\", \"property\"], indicator=False)\n",
    "    print(f\"Positive and Negative Overlapped Dataframe\", flush=True)\n",
    "    print (pos_neg_overlap_df, flush=True)\n",
    "    print()\n",
    "    \n",
    "    pos_neg_df = pd.concat([df, all_neg_data_df], axis=0, ignore_index=True)\n",
    "            \n",
    "    print (\"DF after adding negative data\", flush=True)\n",
    "    print (pos_neg_df.shape, flush=True)\n",
    "    \n",
    "    duplicate_records = pos_neg_df[pos_neg_df.duplicated([\"concept\", \"property\"])]\n",
    "    \n",
    "    print (f\"Duplicate Records : {duplicate_records.shape}\", flush=True)\n",
    "    print (f\"Duplicate record label value count: {duplicate_records['label'].value_counts()}\", flush=True)\n",
    "    print()\n",
    "    \n",
    "    pos_neg_df = pos_neg_df[~pos_neg_df.duplicated(subset=[\"concept\", \"property\"], keep=\"first\")]\n",
    "    \n",
    "    pos_neg_df.drop_duplicates(inplace=True)\n",
    "    pos_neg_df.dropna(how=\"any\", inplace=True)\n",
    "    \n",
    "    pos_neg_df.dropna(axis=0, subset=[\"concept\"], inplace=True)\n",
    "    pos_neg_df.dropna(axis=0, subset=[\"property\"], inplace=True)\n",
    "    pos_neg_df.dropna(axis=0, subset=[\"label\"], inplace=True)\n",
    "    \n",
    "\n",
    "    pos_neg_df = pos_neg_df.sample(frac=1)\n",
    "    \n",
    "    print (f\"Dataframe after removing duplicates : {pos_neg_df.shape}\", flush=True)\n",
    "    \n",
    "    if data_type == \"train\":\n",
    "        pos_neg_df.to_csv(f\"{num_negative}_neg_cslb_train_pos_neg_data.tsv\", sep='\\t', index=None, header=None)\n",
    "    elif data_type == \"test\":\n",
    "        pos_neg_df.to_csv(f\"{num_negative}_neg_cslb_test_pos_neg_data.tsv\", sep='\\t', index=None, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145692ed-41ff-4b7c-9fce-1d85e8f22db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"df_cslb.shape: {df_cslb.shape}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c4a97-0680-406b-95b0-367cfa96b925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd067e-448f-4c9d-a80a-795d6bfdaa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_concepts = df_cslb[\"concept\"].unique()\n",
    "\n",
    "print (f\"Unique Concepts : {len(unique_concepts)}\", flush=True)\n",
    "\n",
    "test_concepts = np.random.choice(a=unique_concepts, size = int(0.1 * len(unique_concepts)), replace=False)\n",
    "\n",
    "print (f\"Number of test concepts : {len(test_concepts)}\", flush=True)\n",
    "\n",
    "test_df = df_cslb[df_cslb[\"concept\"].isin(test_concepts)]\n",
    "train_df = df_cslb[~df_cslb[\"concept\"].isin(test_concepts)]\n",
    "\n",
    "print ()\n",
    "print (\"Total CSLB DF shape :\", df_cslb.shape, flush=True)\n",
    "print (\"Train DF shape :\", train_df.shape, train_df.columns, flush=True)\n",
    "print (\"Test DF shape :\", test_df.shape, test_df.columns, flush=True)\n",
    "\n",
    "print (\"Checking Train Test DF Merge\", flush=True)\n",
    "df1 = train_df.merge(test_df, how=\"inner\", on = [\"concept\"], indicator=False )\n",
    "\n",
    "print (df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47dd54-de8f-42f8-a11f-56686c4d314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"************ Generating Negative Train Data ************\", flush=True)\n",
    "\n",
    "negative_sampling(train_df, \"train\", num_negative=20)\n",
    "\n",
    "print (f\"************ Generating Negative Test Data ************\", flush=True)\n",
    "negative_sampling(test_df, \"test\", num_negative=20)\n",
    "\n",
    "print (f\"************ Negative Data Generation Process Ends ************\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a4744-0bfb-48f0-945b-2e2fb1a43389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3dcba4-a2ef-42db-84ae-6a5af80fe875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8aac3-bd9e-4c46-a558-e9ad2e408e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38007b73-b70e-41dc-be36-a6d5e4b4fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cslb_train_file = \"/home/amitgajbhiye/cardiff_work/siamese_concept_property/data/evaluation_data/CSLB/20_neg_cslb_train_pos_neg_data.tsv\"\n",
    "cslb_test_file = \"/home/amitgajbhiye/cardiff_work/siamese_concept_property/data/evaluation_data/CSLB/20_neg_cslb_test_pos_neg_data.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92343bce-c21d-49db-8b71-9336a46d23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(cslb_train_file, sep=\"\\t\", names=[\"concept\", \"property\", \"label\"])\n",
    "test_df = pd.read_csv(cslb_test_file, sep=\"\\t\", names=[\"concept\", \"property\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb57aa6-814d-4149-ba15-ffd4516306b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224553, 3)\n",
      "(24108, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print (test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7aab4aa-4430-43f8-a475-7ad991d75cad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>property</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22213</th>\n",
       "      <td>barrel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26346</th>\n",
       "      <td>mosquito</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51889</th>\n",
       "      <td>jam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83771</th>\n",
       "      <td>coffee_machine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92476</th>\n",
       "      <td>salmon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99553</th>\n",
       "      <td>tortoise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117245</th>\n",
       "      <td>pigeon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119950</th>\n",
       "      <td>flea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123811</th>\n",
       "      <td>butter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125050</th>\n",
       "      <td>accordion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126378</th>\n",
       "      <td>mayonnaise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128865</th>\n",
       "      <td>cauliflower</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129257</th>\n",
       "      <td>arm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143306</th>\n",
       "      <td>necklace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174159</th>\n",
       "      <td>buzzard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190673</th>\n",
       "      <td>zebra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198381</th>\n",
       "      <td>tent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205120</th>\n",
       "      <td>spatula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220266</th>\n",
       "      <td>gerbil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               concept property  label\n",
       "22213           barrel      NaN      0\n",
       "26346         mosquito      NaN      0\n",
       "51889              jam      NaN      0\n",
       "83771   coffee_machine      NaN      0\n",
       "92476           salmon      NaN      0\n",
       "99553         tortoise      NaN      0\n",
       "117245          pigeon      NaN      0\n",
       "119950            flea      NaN      0\n",
       "123811          butter      NaN      0\n",
       "125050       accordion      NaN      0\n",
       "126378      mayonnaise      NaN      0\n",
       "128865     cauliflower      NaN      0\n",
       "129257             arm      NaN      0\n",
       "143306        necklace      NaN      0\n",
       "174159         buzzard      NaN      0\n",
       "190673           zebra      NaN      0\n",
       "198381            tent      NaN      1\n",
       "205120         spatula      NaN      0\n",
       "220266          gerbil      NaN      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"property\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad74b2e9-3c98-447e-90f4-674ce191660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=[\"property\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5607cca5-6f28-4e56-8237-85ad7f3a69b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224534, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5274091d-084a-43fe-8019-0e2f757e6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=[\"concept\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c33763-b525-437f-b7fd-229bb3775d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224534, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e21c19-b965-440e-9a18-4ad6abf93c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = train_df.merge(test_df, how=\"inner\", on = [\"concept\", \"property\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8753be-5332-4ccc-9199-9b9c1b792a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b5cd1-1ccb-4904-a3f5-6dc2edb4bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = train_df.merge(test_df, how=\"inner\", on = [\"concept\", \"property\"])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e0e97-6cdb-4217-b33c-1decf21f3905",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = train_df.merge(test_df, how=\"inner\", on = [\"concept\"])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbae969-b830-41d9-8b88-1fd7f5a8cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f50292-a175-4c4e-91fa-1951b4c11b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=[\"property\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d601dc-dbef-49d1-9684-ba2e9209b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922b6e3-f093-4e86-be58-b3784e469659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df = pd.concat((train_df, test_df), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a6f768-9bdb-4bdb-9f94-c76ace372040",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e2dd4-da29-49a8-93fb-a5e739ae9bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df.index.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2653edc-7004-4f44-b028-0a2dfad02d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df.dropna(how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc5248-134f-43d5-b741-fa93026996ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae6e24-c6d9-4730-9e54-cb9ab46d0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df[train_and_test_df[\"property\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233a8bf-72e2-454b-9d15-60587c0bfcfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4845e4b-46a8-4947-98a3-b40c36dd32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df[train_and_test_df[\"property\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42821e4f-ce13-49dc-b6a1-9039a92e6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df = train_and_test_df.dropna(subset=[\"property\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aaaa3c-6ab9-416a-8c84-d1d61f88c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a0169-0ab1-492c-a61b-6b6f4b7be0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df[train_and_test_df[\"property\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e61c2-32fa-42a1-927e-3c4d0d8e87e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df[train_and_test_df[\"concept\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10771df-cb56-47c1-84a9-943a880df4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df[train_and_test_df[\"label\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c978618-ce08-4a67-aa54-2951f26b522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df[~train_and_test_df.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e4fdd-151c-494d-905b-4ee263a4d3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b883d98d-d83f-43c8-adca-344a8e278032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7bb87-7280-4604-bfdc-0c6cec764fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c098b37-d7a9-44a5-80d8-2cdf8a27ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626125f9-5971-4d63-bd86-1f99009888d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df.set_index(\"property\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3aba1-115d-44e8-8e8f-652e0b4e73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042c88d-e71a-4f8d-b803-d64a7dd8b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df.reset_index(inplace=True)\n",
    "train_and_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef676f86-a4a3-40db-aeb0-4997ff953cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df[train_and_test_df.duplicated(subset=[\"concept\", \"property\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a1d99-59ef-4ced-96fe-d19f654f5790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba83167-4106-491b-8309-c535afabe3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e6d7c7-285a-47da-9d64-e44ebee72cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
