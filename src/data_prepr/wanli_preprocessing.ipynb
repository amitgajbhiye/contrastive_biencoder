{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "430f516c-2239-44b8-9a3d-2e1af5c711d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e986186-ac7a-4e04-a7f4-26d9e98cc98d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Split : train\n",
      "save_file_path : ./../../data/train_data/je_con_prop/wanli\n",
      "Size of Loaded DF : (102885, 7)\n",
      "Columnns of Loaded DF : Index(['id', 'premise', 'hypothesis', 'gold', 'genre', 'pairID', 'label'], dtype='object')\n",
      "Loaded train DF\n",
      "        id                                            premise  \\\n",
      "0    70337  For more than a decade, the town has had a cur...   \n",
      "1    82936  There is no doubt that, at the time, there was...   \n",
      "2   251517                                    It was raining.   \n",
      "3   209566  In the early days of the settlement, a few bra...   \n",
      "4   201418  He believes that the health care system will n...   \n",
      "5   370019  It is possible that the Senate will vote to ke...   \n",
      "6   214335  To determine whether the demand for the produc...   \n",
      "7   341367  In addition, some authors have recommended tha...   \n",
      "8    45016  For the same reason, it is often said that, in...   \n",
      "9   371909  I couldn't help but think that he'd been a bit...   \n",
      "10  371411  But I was also angry that he had not told me t...   \n",
      "11  150290  The air pollution problem is something that af...   \n",
      "12  345334  The first two chapters discuss the nature of w...   \n",
      "13  243623                     A student said to his teacher:   \n",
      "14  256093                               It's very dangerous.   \n",
      "15    8230  The model has been based on the generalization...   \n",
      "16  124061       We'll be able to see the Great Barrier Reef.   \n",
      "17   67911  The demand for many of these materials is high...   \n",
      "18   63224  They have been known to appear on motorways, e...   \n",
      "19  278568  The last of the three is a small boy who had t...   \n",
      "\n",
      "                                           hypothesis        gold  \\\n",
      "0   The town has a curfew for children, but it is ...     neutral   \n",
      "1   There is no doubt that the government was supp...     neutral   \n",
      "2                         It was raining at the time.  entailment   \n",
      "3                        The pioneers lived in caves.  entailment   \n",
      "4   The health care system will not be able to han...     neutral   \n",
      "5   The Senate will not vote to keep the president...     neutral   \n",
      "6   To determine whether the demand for the produc...  entailment   \n",
      "7   It is not necessary to find the causes of fals...     neutral   \n",
      "8   The economy's leading figures are usually peop...     neutral   \n",
      "9                                  He was distracted.     neutral   \n",
      "10  I was angry that he had not told me that he wa...     neutral   \n",
      "11             Everyone is affected by air pollution.  entailment   \n",
      "12  The work and family relationship is not as imp...     neutral   \n",
      "13             A student asked his teacher a question     neutral   \n",
      "14            It's very dangerous to get mixed up in.     neutral   \n",
      "15  The model has been based on generalizations of...  entailment   \n",
      "16  The Great Barrier Reef will be visible from th...     neutral   \n",
      "17  The price of raw materials is less elastic tha...     neutral   \n",
      "18           There are many motorways in the country.     neutral   \n",
      "19                    The small boy was in the water.  entailment   \n",
      "\n",
      "                genre  pairID  label  \n",
      "0           generated  185334      0  \n",
      "1           generated  227256      0  \n",
      "2           generated  184721      1  \n",
      "3           generated  100143      1  \n",
      "4           generated   42641      0  \n",
      "5           generated  110759      0  \n",
      "6           generated   52593      1  \n",
      "7           generated   78764      0  \n",
      "8   generated_revised  385051      0  \n",
      "9           generated   69843      0  \n",
      "10  generated_revised  246137      0  \n",
      "11          generated   87208      1  \n",
      "12          generated   24341      0  \n",
      "13          generated  107268      0  \n",
      "14          generated  278402      0  \n",
      "15          generated   18049      1  \n",
      "16          generated  138718      0  \n",
      "17          generated  367903      0  \n",
      "18          generated  379846      0  \n",
      "19          generated    8714      1  \n",
      "Label Value Counts : 0    64374\n",
      "1    38511\n",
      "Name: label, dtype: int64\n",
      "Train Data Cols : Index(['id', 'premise', 'hypothesis', 'gold', 'genre', 'pairID'], dtype='object')\n",
      "Train Label Data Cols : Index(['label'], dtype='object')\n",
      "\n",
      "Train Data : (92596, 6) (92596, 1)\n",
      "Valid Data : (10289, 6) (10289, 1)\n",
      "Train DF Shape : (92596, 3)\n",
      "Train Label Count : 0    57936\n",
      "1    34660\n",
      "Name: label, dtype: int64\n",
      "Train DF NaN : premise       False\n",
      "hypothesis    False\n",
      "label         False\n",
      "dtype: bool\n",
      "\n",
      "Valid DF Shape : (10289, 3)\n",
      "Valid Label Count : 0    6438\n",
      "1    3851\n",
      "Name: label, dtype: int64\n",
      "Valid DF NaN : premise       False\n",
      "hypothesis    False\n",
      "label         False\n",
      "dtype: bool\n",
      "\n",
      "Data Split : test\n",
      "save_file_path : ./../../data/train_data/je_con_prop/wanli\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './../../data/train_data/je_con_prop/wanli/test.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 97\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest DF NaN : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_df\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m preprocess_wanli(json_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./../../data/train_data/je_con_prop/wanli/train.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m \u001b[43mpreprocess_wanli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./../../data/train_data/je_con_prop/wanli/test.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m, in \u001b[0;36mpreprocess_wanli\u001b[0;34m(json_file_name, data_split)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Split : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_split\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_file_path : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m jfile:    \n\u001b[1;32m     10\u001b[0m     all_data \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mloads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m jfile]    \n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_label\u001b[39m(gold_class):\n",
      "File \u001b[0;32m~/miniconda3/envs/gvenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './../../data/train_data/je_con_prop/wanli/test.jsonl'"
     ]
    }
   ],
   "source": [
    "def preprocess_wanli (json_file_name, data_split):\n",
    "    \n",
    "    save_file_path, _ = os.path.split(json_file_name)\n",
    "    \n",
    "    print ()\n",
    "    print (f\"Data Split : {data_split}\")\n",
    "    print (f\"save_file_path : {save_file_path}\")\n",
    "    \n",
    "    with open(json_file_name, \"r\") as jfile:    \n",
    "        all_data = [json.loads(line) for line in jfile]    \n",
    "    \n",
    "    def create_label(gold_class):\n",
    "        label_dict = {'entailment' : 1, 'contradiction': 0, 'neutral': 0}    \n",
    "        return int(label_dict[gold_class])\n",
    "    \n",
    "    data_df = pd.DataFrame.from_dict(all_data, orient=\"columns\")\n",
    "    \n",
    "    data_df[\"label\"] = data_df[\"gold\"].apply(create_label)\n",
    "    \n",
    "    print (f\"Size of Loaded DF : {data_df.shape}\")\n",
    "    print (f\"Columnns of Loaded DF : {data_df.columns}\")\n",
    "    print (f\"Loaded {data_split} DF\")\n",
    "    print (data_df.head(n=20))\n",
    "    print (f\"Label Value Counts : {data_df['label'].value_counts()}\")\n",
    "    \n",
    "    \n",
    "    save_cols = [\"premise\", \"hypothesis\", \"label\"]\n",
    "    \n",
    "    if data_split == \"train\":\n",
    "        \n",
    "        col_names = data_df.columns\n",
    "        \n",
    "        X_col = [col for col in col_names if col != \"label\"]\n",
    "        y_col = [\"label\"]\n",
    "        \n",
    "        X = data_df[X_col]\n",
    "        y = data_df[y_col].astype(\"int32\")\n",
    "        \n",
    "        print (f\"Train Data Cols : {X.columns}\")\n",
    "        print (f\"Train Label Data Cols : {y.columns}\")\n",
    "        \n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=111, test_size=0.10, shuffle=True, stratify=y)\n",
    "\n",
    "        print ()\n",
    "        print (\"Train Data :\", X_train.shape, y_train.shape)\n",
    "        print (\"Valid Data :\", X_valid.shape, y_valid.shape)\n",
    "\n",
    "        train_df = pd.concat((X_train, y_train), axis=1)\n",
    "        \n",
    "        processed_file_path = os.path.join(save_file_path, f\"processed_{data_split}.tsv\")\n",
    "        train_df.to_csv(processed_file_path, sep=\"\\t\", header=None, index=None)\n",
    "        \n",
    "        train_df = train_df[save_cols]\n",
    "        \n",
    "        final_file_path = os.path.join(save_file_path, f\"{data_split}.tsv\")\n",
    "        train_df.to_csv(final_file_path, sep=\"\\t\", header=None, index=None)\n",
    "                \n",
    "        ### Valid Data ###\n",
    "        valid_df = pd.concat((X_valid, y_valid), axis=1)\n",
    "        \n",
    "        processed_file_path = os.path.join(save_file_path, f\"processed_valid.tsv\")\n",
    "        valid_df.to_csv(processed_file_path, sep=\"\\t\", header=None, index=None)\n",
    "        \n",
    "        valid_df = valid_df[save_cols]\n",
    "        \n",
    "        final_file_path = os.path.join(save_file_path, f\"valid.tsv\")\n",
    "        valid_df.to_csv(final_file_path, sep=\"\\t\", header=None, index=None)\n",
    "        \n",
    "        print (f\"Train DF Shape : {train_df.shape}\")\n",
    "        print (f\"Train Label Count : {train_df['label'].value_counts()}\")\n",
    "        print (f\"Train DF NaN : {train_df.isna().any()}\")\n",
    "        \n",
    "        \n",
    "        print ()\n",
    "        print (f\"Valid DF Shape : {valid_df.shape}\")\n",
    "        print (f\"Valid Label Count : {valid_df['label'].value_counts()}\")\n",
    "        print (f\"Valid DF NaN : {valid_df.isna().any()}\")\n",
    "        \n",
    "    \n",
    "    elif data_split == \"test\":\n",
    "        \n",
    "        processed_file_path = os.path.join(save_file_path, f\"processed_{data_split}.tsv\")\n",
    "        data_df.to_csv(processed_file_path, sep=\"\\t\", header=None, index=None)\n",
    "        \n",
    "        data_df = data_df[save_cols]\n",
    "        \n",
    "        final_file_path = os.path.join(save_file_path, f\"{data_split}.tsv\")\n",
    "        data_df.to_csv(final_file_path, sep=\"\\t\", header=None, index=None)\n",
    "                \n",
    "        print ()\n",
    "        print (f\"Test DF Shape : {data_df.shape}\")\n",
    "        print (f\"Test Label Count : {data_df['label'].value_counts()}\")\n",
    "        print (f\"Test DF NaN : {data_df.isna().any()}\")\n",
    "\n",
    "            \n",
    "preprocess_wanli(json_file_name = \"./../../data/train_data/je_con_prop/wanli/train.jsonl\", data_split=\"train\")\n",
    "preprocess_wanli(json_file_name = \"./../../data/train_data/je_con_prop/wanli/test.jsonl\", data_split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4897bcc-7409-4aa1-bf92-bb1a8f9bed69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8adef-3f9e-4e27-80a9-2b357cefa6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971a81d-e8d2-4e18-9cf9-1b38ebaaf12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
