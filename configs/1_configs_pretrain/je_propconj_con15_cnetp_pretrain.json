{
    "experiment_name": "je_propconj_con15_cnetp_pretrain",
    "log_dirctory": "pretrain",
    "training_params": {
        "dataset_name": "cnetp_con15",
        "pretrain": true,
        "train_file_path": "data/train_data/je_prop_conj/con15_5_neg_train_cnet_premium.tsv",
        "val_file_path": "data/train_data/je_prop_conj/con15_5_neg_valid_cnet_premium.tsv",
        "finetune": false,
        "load_pretrained": false,
        "pretrained_model_path": null,
        "cv_type": null,
        "data_dir": null,
        "batch_size": 64,
        "lr": 2e-6,
        "max_epochs": 100,
        "num_warmup_steps": 0,
        "patience_early_stopping": 10,
        "save_dir": "trained_models/je_prop_conj_cnetp_pretrained",
        "model_name": "je_propconj_con15_cnetp_pretrain.pt",
        "lr_policy": null,
        "lr_decay_iters": null
    },
    "dataset_params": {
        "hf_tokenizer_name": "bert-base-uncased",
        "hf_tokenizer_path": "/scratch/c.scmag3/conceptEmbeddingModel/for_seq_classification_bert_base_uncased/tokenizer",
        "max_len": 128
    },
    "model_params": {
        "hf_checkpoint_name": "bert-base-uncased",
        "hf_model_path": "/scratch/c.scmag3/conceptEmbeddingModel/for_seq_classification_bert_base_uncased/model",
        "num_labels": 2
    }
}