{
    "experiment_name": "wanli_pretrained_roberta_large_pretrain_mask_id_ctx1_con_prop_cnetp",
    "log_dirctory": "pretrain",
    "training_params": {
        "dataset_name": "cnetp_con_prop_5neg",
        "pretrain": true,
        "train_file_path": "data/train_data/je_con_prop/5_neg_train_cnet_premium.tsv",
        "val_file_path": "data/train_data/je_con_prop/5_neg_valid_cnet_premium.tsv",
        "finetune": false,
        "load_pretrained": false,
        "pretrained_model_path": null,
        "cv_type": null,
        "data_dir": null,
        "batch_size": 32,
        "lr": 1e-5,
        "max_epochs": 100,
        "num_warmup_steps": 0,
        "patience_early_stopping": 5,
        "save_dir": "trained_models/je_con_prop_cnetp_pretrained",
        "model_name": "wanli_pretrained_roberta_large_pretrain_mask_id_ctx1_con_prop_cnetp.pt",
        "lr_policy": null,
        "lr_decay_iters": null,
        "weight_decay": 0.01
    },
    "dataset_params": {
        "hf_tokenizer_name": "roberta-large",
        "hf_tokenizer_path": "/scratch/c.scmag3/hf_pretrained_models/wanli_roberta_large/tokenizer",
        "max_len": 40,
        "context_id": 1
    },
    "model_params": {
        "hf_checkpoint_name": "roberta-large",
        "hf_model_path": "/scratch/c.scmag3/hf_pretrained_models/wanli_roberta_large/model",
        "num_labels": 0,
        "context_id": 1
    }
}